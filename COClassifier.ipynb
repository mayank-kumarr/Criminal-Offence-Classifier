{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COClassifier",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orJS9wrZWKHk",
        "outputId": "3287149b-1da3-48ab-bf40-84875d61174e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.4\n",
            "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4 MB 7.7 kB/s \n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.4.0 which is incompatible.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.4.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.4.0 which is incompatible.\n",
            "fastai 2.6.3 requires torch<1.12,>=1.7.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from argparse import ArgumentParser\n",
        "from gensim.models import KeyedVectors"
      ],
      "metadata": {
        "id": "X1vzBNNynGcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import en_core_web_sm\n",
        "from itertools import groupby"
      ],
      "metadata": {
        "id": "Rn6wndFypA3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.utils.rnn as U\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "-yXFYH7phV67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "4Ky_nvrtpEVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from train import *\n",
        "from models import *\n",
        "from utils.predict_util import *\n",
        "from utils.data_util import *\n",
        "from utils.train_util import prepare_offence"
      ],
      "metadata": {
        "id": "vxZocfzyhgHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"data/\"                   # Folder to store dataset\n",
        "train_file = \"Train-Sent.jsonl\"       # Train dataset\n",
        "test_file = \"Test-Doc.jsonl\"          # Test dataset\n",
        "label_file = \"Labels.jsonl\"           # Charge descriptions\n",
        "save_path = \"saved/\"                  # Folder to store trained model and metrics\n",
        "pretrained = \"ptembs/word2vec.kv\"     # Pretrained word2vec embeddings file\n",
        "                                      # [embedding dimensions must match!]\n",
        "                                      # use 'None' for no pretrained initialization\n",
        "label_wts = True                      # Use weighted loss function\n",
        "vocab_thresh = 2                      # Min frequency for a word to be included in vocabulary\n",
        "embed_dim = 128                       # Embedding dimension\n",
        "epochs = 200                          # Number of training epochs\n",
        "batch_size = 5                        # Batch size\n",
        "device = 'cuda'                       # Device (cuda/cpu)\n",
        "lr = 1e-3                             # Learning rate\n",
        "l2reg = 5e-4                          # L2 Regularization penalty\n",
        "lr_patience = 5                       # Number of epochs of non-increasing performance \n",
        "                                      # to wait before reducing learning rate\n",
        "                                      # use -1 for fixed learning rate\n",
        "lr_factor = 0.5                       # Factor to reduce learning rate by\n",
        "print_every = 1                       # Epoch interval after which metrics will be printed"
      ],
      "metadata": {
        "id": "yn5GfGnAnUHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading and tokenizing fact and charge descriptions\n",
        "traindev_data = jsonl_to_list(data_path + train_file)\n",
        "test_data = jsonl_to_list(data_path + test_file)\n",
        "label_data = jsonl_to_list(data_path + label_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lmriy-Jn8Qy",
        "outputId": "62447b63-ebe3-4438-d9f9-728ddd513062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "120it [00:13,  9.10it/s]\n",
            "70it [00:08,  8.19it/s]\n",
            "20it [00:00, 29.16it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_docs = len(traindev_data)\n",
        "num_sents = len(sum([doc['text'] for doc in traindev_data], []))"
      ],
      "metadata": {
        "id": "9yp4InKeoMt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Creating vocab...\")\n",
        "word_freq = defaultdict(int)\n",
        "sent_label_freq = defaultdict(int)\n",
        "doc_label_freq = defaultdict(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxbzLHZ5ociY",
        "outputId": "6cf2e123-b898-4400-ab9b-979e4a9037c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating vocab...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calc_freq(traindev_data, word_freq, sent_label_freq, doc_label_freq)\n",
        "calc_freq(label_data, word_freq)"
      ],
      "metadata": {
        "id": "k5dSTVslohUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_vocab = get_label_vocab(label_data)\n",
        "vocab = get_vocab(word_freq)\n",
        "ptemb_matrix = None"
      ],
      "metadata": {
        "id": "Tuv0ydjkonoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing all data\n",
        "tokenize_dataset(traindev_data, vocab, label_vocab)\n",
        "tokenize_dataset(test_data, vocab, label_vocab)\n",
        "tokenize_dataset(label_data, vocab, label_vocab)"
      ],
      "metadata": {
        "id": "H7F6zBPiouAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting label weights\n",
        "if label_wts:\n",
        "    sent_label_wts = torch.from_numpy(get_label_weights(label_vocab, sent_label_freq, num_sents)).to(device)\n",
        "    doc_label_wts = torch.from_numpy(get_label_weights(label_vocab, doc_label_freq, num_docs)).to(device)\n",
        "else:\n",
        "    sent_label_wts = None\n",
        "    doc_label_wts = None"
      ],
      "metadata": {
        "id": "k49GajhVozMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing label data and model\n",
        "charges = prepare_offence(label_data)"
      ],
      "metadata": {
        "id": "ndrkDocYpLe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = COClassifier(len(vocab), embed_dim, len(label_vocab), charges['offence'], charges['sent_lens'], charges['doc_lens'], device, sent_label_wts, doc_label_wts, ptemb_matrix).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=l2reg)"
      ],
      "metadata": {
        "id": "us07D35apRNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = None\n",
        "if lr_patience != -1:\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=lr_patience, factor=lr_factor, verbose=True)"
      ],
      "metadata": {
        "id": "Iahf4yqKpZZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics, model1 = train(model, traindev_data, test_data, optimizer, \n",
        "    lr_scheduler=scheduler, epochs=epochs, batch_size=batch_size, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lNblRqrpfjb",
        "outputId": "311fb993-73af-4ba8-ee4d-a5d6de6d7ad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training...\n",
            "\n",
            "EPOCH ||  Tr-LOSS |    Tr-F1 ||  Dv-LOSS |     Dv-P     Dv-R    Dv-F1\n",
            "    1 ||   2.8759 |   0.1262 ||   1.2815 |   0.1015   0.6146   0.1231\n",
            "    2 ||   2.7575 |   0.1431 ||   1.2664 |   0.1284   0.6821   0.1887\n",
            "    3 ||   2.6921 |   0.1400 ||   1.2742 |   0.1463   0.5368   0.1558\n",
            "    4 ||   2.6646 |   0.1321 ||   1.2522 |   0.1049   0.5524   0.1551\n",
            "    5 ||   2.6354 |   0.1544 ||   1.2652 |   0.1309   0.5597   0.1979\n",
            "    6 ||   2.6215 |   0.1547 ||   1.2451 |   0.1613   0.5236   0.1961\n",
            "    7 ||   2.5453 |   0.1726 ||   1.2345 |   0.1768   0.5415   0.2159\n",
            "    8 ||   2.5312 |   0.2477 ||   1.2077 |   0.1844   0.6824   0.2549\n",
            "    9 ||   2.4395 |   0.2166 ||   1.1828 |   0.2136   0.6181   0.2977\n",
            "   10 ||   2.3500 |   0.2430 ||   1.1347 |   0.2010   0.7150   0.2814\n",
            "   11 ||   2.2739 |   0.2950 ||   1.1856 |   0.2244   0.6613   0.2738\n",
            "   12 ||   2.2648 |   0.2792 ||   1.1800 |   0.2454   0.6340   0.3183\n",
            "   13 ||   2.1529 |   0.3350 ||   1.1001 |   0.2311   0.6762   0.3209\n",
            "   14 ||   2.1587 |   0.3260 ||   1.1183 |   0.2716   0.5813   0.3133\n",
            "   15 ||   2.1273 |   0.3293 ||   1.1420 |   0.2404   0.5802   0.3242\n",
            "   16 ||   2.0633 |   0.3689 ||   1.1520 |   0.2045   0.5239   0.2574\n",
            "   17 ||   2.1000 |   0.3463 ||   1.1235 |   0.2450   0.5488   0.3191\n",
            "   18 ||   2.0368 |   0.3484 ||   1.1245 |   0.2769   0.5059   0.3035\n",
            "   19 ||   2.0180 |   0.3518 ||   1.1709 |   0.2383   0.5529   0.3131\n",
            "   20 ||   2.0157 |   0.3865 ||   1.1273 |   0.2318   0.5514   0.3014\n",
            "Epoch    21: reducing learning rate of group 0 to 5.0000e-04.\n",
            "   21 ||   1.9501 |   0.3963 ||   1.1558 |   0.2611   0.5222   0.3165\n",
            "   22 ||   1.9218 |   0.4191 ||   1.1206 |   0.2811   0.5886   0.3630\n",
            "   23 ||   1.8105 |   0.4711 ||   1.0779 |   0.3057   0.5948   0.3822\n",
            "   24 ||   1.8494 |   0.4177 ||   1.1071 |   0.2885   0.4947   0.3298\n",
            "   25 ||   1.8642 |   0.4512 ||   1.1864 |   0.2647   0.4976   0.3187\n",
            "   26 ||   1.8132 |   0.5176 ||   1.1514 |   0.2749   0.5652   0.3468\n",
            "   27 ||   1.7840 |   0.4995 ||   1.1510 |   0.3071   0.5263   0.3545\n",
            "   28 ||   1.8350 |   0.4455 ||   1.1695 |   0.2818   0.4889   0.3416\n",
            "Epoch    29: reducing learning rate of group 0 to 2.5000e-04.\n",
            "   29 ||   1.7964 |   0.4571 ||   1.1243 |   0.3145   0.5178   0.3634\n",
            "   30 ||   1.7634 |   0.4520 ||   1.1744 |   0.3064   0.4483   0.3301\n",
            "   31 ||   1.7141 |   0.5179 ||   1.1888 |   0.2972   0.5168   0.3453\n",
            "   32 ||   1.7979 |   0.4507 ||   1.1774 |   0.2925   0.5083   0.3508\n",
            "   33 ||   1.7230 |   0.5165 ||   1.2495 |   0.2749   0.4438   0.3189\n",
            "   34 ||   1.7811 |   0.5031 ||   1.1813 |   0.3145   0.5122   0.3649\n",
            "Epoch    35: reducing learning rate of group 0 to 1.2500e-04.\n",
            "   35 ||   1.7417 |   0.4632 ||   1.1523 |   0.3311   0.5003   0.3708\n",
            "   36 ||   1.7344 |   0.5123 ||   1.1840 |   0.3269   0.5183   0.3793\n",
            "   37 ||   1.6958 |   0.4943 ||   1.1454 |   0.3269   0.4961   0.3672\n",
            "   38 ||   1.7192 |   0.5270 ||   1.1516 |   0.3157   0.4948   0.3547\n",
            "   39 ||   1.7200 |   0.4725 ||   1.2395 |   0.2878   0.4266   0.3192\n",
            "   40 ||   1.7574 |   0.5165 ||   1.2441 |   0.3100   0.4628   0.3426\n",
            "   41 ||   1.7497 |   0.4880 ||   1.1330 |   0.3644   0.5105   0.3994\n",
            "   42 ||   1.6999 |   0.5106 ||   1.1851 |   0.3127   0.4482   0.3456\n",
            "   43 ||   1.7390 |   0.4849 ||   1.1801 |   0.3445   0.4440   0.3585\n",
            "   44 ||   1.7199 |   0.5163 ||   1.2135 |   0.3214   0.4549   0.3522\n",
            "   45 ||   1.6688 |   0.5336 ||   1.2486 |   0.3072   0.4358   0.3386\n",
            "   46 ||   1.7219 |   0.5289 ||   1.2478 |   0.2915   0.4344   0.3161\n",
            "Epoch    47: reducing learning rate of group 0 to 6.2500e-05.\n",
            "   47 ||   1.7372 |   0.5101 ||   1.2164 |   0.2946   0.4925   0.3442\n",
            "   48 ||   1.6787 |   0.5280 ||   1.2043 |   0.3119   0.4855   0.3501\n",
            "   49 ||   1.6549 |   0.5729 ||   1.2176 |   0.3356   0.5114   0.3750\n",
            "   50 ||   1.6337 |   0.5626 ||   1.2234 |   0.3140   0.4295   0.3431\n",
            "   51 ||   1.6669 |   0.5301 ||   1.2241 |   0.3410   0.4651   0.3557\n",
            "   52 ||   1.6249 |   0.5557 ||   1.2051 |   0.3083   0.4260   0.3329\n",
            "Epoch    53: reducing learning rate of group 0 to 3.1250e-05.\n",
            "   53 ||   1.6364 |   0.5320 ||   1.1987 |   0.3259   0.4752   0.3567\n",
            "   54 ||   1.6576 |   0.5155 ||   1.1597 |   0.3793   0.4813   0.3938\n",
            "   55 ||   1.6726 |   0.5266 ||   1.2428 |   0.2839   0.4180   0.3229\n",
            "   56 ||   1.7047 |   0.5355 ||   1.2665 |   0.3253   0.4405   0.3514\n",
            "   57 ||   1.6525 |   0.5402 ||   1.2040 |   0.3598   0.4585   0.3716\n",
            "   58 ||   1.6612 |   0.5380 ||   1.2511 |   0.2767   0.4098   0.3106\n",
            "Epoch    59: reducing learning rate of group 0 to 1.5625e-05.\n",
            "   59 ||   1.7139 |   0.5172 ||   1.2977 |   0.2951   0.4153   0.3268\n",
            "   60 ||   1.6944 |   0.5375 ||   1.2553 |   0.3137   0.4301   0.3353\n",
            "   61 ||   1.6855 |   0.5676 ||   1.2641 |   0.3207   0.4138   0.3403\n",
            "   62 ||   1.6862 |   0.5015 ||   1.1958 |   0.3379   0.4972   0.3703\n",
            "   63 ||   1.6874 |   0.4968 ||   1.1881 |   0.3490   0.4451   0.3643\n",
            "   64 ||   1.6828 |   0.5767 ||   1.2249 |   0.3377   0.4462   0.3593\n",
            "Epoch    65: reducing learning rate of group 0 to 7.8125e-06.\n",
            "   65 ||   1.7132 |   0.4839 ||   1.2121 |   0.3386   0.4429   0.3616\n",
            "   66 ||   1.6847 |   0.5536 ||   1.2058 |   0.3616   0.4795   0.3885\n",
            "   67 ||   1.6366 |   0.5046 ||   1.2005 |   0.3660   0.5037   0.3972\n",
            "   68 ||   1.6787 |   0.5451 ||   1.3100 |   0.2944   0.4478   0.3328\n",
            "   69 ||   1.7038 |   0.5313 ||   1.2226 |   0.3540   0.4735   0.3791\n",
            "   70 ||   1.6172 |   0.6139 ||   1.2560 |   0.3350   0.4657   0.3608\n",
            "Epoch    71: reducing learning rate of group 0 to 3.9063e-06.\n",
            "   71 ||   1.6602 |   0.5137 ||   1.2080 |   0.3189   0.4556   0.3558\n",
            "   72 ||   1.6829 |   0.4980 ||   1.2108 |   0.3348   0.4245   0.3394\n",
            "   73 ||   1.6174 |   0.5634 ||   1.2613 |   0.3137   0.4855   0.3623\n",
            "   74 ||   1.6483 |   0.5574 ||   1.2984 |   0.2944   0.3963   0.3194\n",
            "   75 ||   1.6616 |   0.5275 ||   1.2350 |   0.3078   0.4236   0.3366\n",
            "   76 ||   1.6968 |   0.4831 ||   1.1774 |   0.3369   0.4408   0.3608\n",
            "Epoch    77: reducing learning rate of group 0 to 1.9531e-06.\n",
            "   77 ||   1.6996 |   0.5100 ||   1.2253 |   0.3094   0.4187   0.3355\n",
            "   78 ||   1.6912 |   0.5175 ||   1.1979 |   0.3835   0.4713   0.3862\n",
            "   79 ||   1.7011 |   0.5296 ||   1.2281 |   0.3332   0.4732   0.3679\n",
            "   80 ||   1.6292 |   0.5823 ||   1.2553 |   0.3275   0.4424   0.3486\n",
            "   81 ||   1.6715 |   0.4914 ||   1.2344 |   0.3191   0.4412   0.3472\n",
            "   82 ||   1.6605 |   0.5276 ||   1.1403 |   0.3622   0.4733   0.3766\n",
            "Epoch    83: reducing learning rate of group 0 to 9.7656e-07.\n",
            "   83 ||   1.6382 |   0.5674 ||   1.2870 |   0.3084   0.4299   0.3379\n",
            "   84 ||   1.6925 |   0.5138 ||   1.2180 |   0.3552   0.4782   0.3816\n",
            "   85 ||   1.7174 |   0.5114 ||   1.2282 |   0.3103   0.4280   0.3358\n",
            "   86 ||   1.6862 |   0.5084 ||   1.1852 |   0.3173   0.4371   0.3385\n",
            "   87 ||   1.6788 |   0.5338 ||   1.1477 |   0.3375   0.4793   0.3660\n",
            "   88 ||   1.6878 |   0.5328 ||   1.2309 |   0.3342   0.4357   0.3488\n",
            "Epoch    89: reducing learning rate of group 0 to 4.8828e-07.\n",
            "   89 ||   1.6730 |   0.5490 ||   1.2485 |   0.3213   0.4038   0.3286\n",
            "   90 ||   1.6352 |   0.5428 ||   1.2383 |   0.2852   0.4166   0.3209\n",
            "   91 ||   1.6794 |   0.4749 ||   1.1978 |   0.3510   0.4604   0.3713\n",
            "   92 ||   1.6892 |   0.5202 ||   1.2308 |   0.3334   0.4257   0.3463\n",
            "   93 ||   1.7410 |   0.4921 ||   1.2235 |   0.3547   0.4557   0.3632\n",
            "   94 ||   1.6363 |   0.5542 ||   1.2522 |   0.3754   0.4545   0.3691\n",
            "Epoch    95: reducing learning rate of group 0 to 2.4414e-07.\n",
            "   95 ||   1.7304 |   0.5009 ||   1.1985 |   0.3138   0.4294   0.3330\n",
            "   96 ||   1.6905 |   0.5410 ||   1.1802 |   0.3314   0.4363   0.3531\n",
            "   97 ||   1.6953 |   0.5182 ||   1.2549 |   0.3208   0.4232   0.3362\n",
            "   98 ||   1.6310 |   0.5454 ||   1.3072 |   0.3074   0.3856   0.3158\n",
            "   99 ||   1.6635 |   0.5335 ||   1.2301 |   0.3387   0.4411   0.3565\n",
            "  100 ||   1.6423 |   0.5299 ||   1.2482 |   0.3410   0.4621   0.3664\n",
            "Epoch   101: reducing learning rate of group 0 to 1.2207e-07.\n",
            "  101 ||   1.6839 |   0.5481 ||   1.2298 |   0.3584   0.4591   0.3701\n",
            "  102 ||   1.6829 |   0.5313 ||   1.2755 |   0.3112   0.4068   0.3194\n",
            "  103 ||   1.7108 |   0.4698 ||   1.2455 |   0.3372   0.4545   0.3678\n",
            "  104 ||   1.6798 |   0.5259 ||   1.2233 |   0.4012   0.4518   0.3911\n",
            "  105 ||   1.6587 |   0.5215 ||   1.2155 |   0.3438   0.4389   0.3556\n",
            "  106 ||   1.6399 |   0.5335 ||   1.2480 |   0.3332   0.4186   0.3434\n",
            "Epoch   107: reducing learning rate of group 0 to 6.1035e-08.\n",
            "  107 ||   1.6545 |   0.5719 ||   1.2272 |   0.3707   0.4560   0.3733\n",
            "  108 ||   1.6901 |   0.5383 ||   1.2771 |   0.3393   0.4231   0.3376\n",
            "  109 ||   1.6983 |   0.5454 ||   1.2137 |   0.3899   0.4770   0.3786\n",
            "  110 ||   1.6664 |   0.5464 ||   1.2393 |   0.3007   0.4148   0.3310\n",
            "  111 ||   1.6938 |   0.5109 ||   1.2273 |   0.3501   0.4950   0.3826\n",
            "  112 ||   1.6631 |   0.5394 ||   1.1935 |   0.3302   0.4446   0.3462\n",
            "Epoch   113: reducing learning rate of group 0 to 3.0518e-08.\n",
            "  113 ||   1.6273 |   0.5433 ||   1.2222 |   0.2925   0.4046   0.3229\n",
            "  114 ||   1.6694 |   0.5041 ||   1.2096 |   0.3521   0.4815   0.3749\n",
            "  115 ||   1.6616 |   0.5267 ||   1.1873 |   0.3468   0.4913   0.3862\n",
            "  116 ||   1.6823 |   0.5025 ||   1.2092 |   0.3236   0.4277   0.3368\n",
            "  117 ||   1.6391 |   0.5233 ||   1.2110 |   0.3885   0.4676   0.3794\n",
            "  118 ||   1.6134 |   0.5981 ||   1.1797 |   0.3174   0.4666   0.3497\n",
            "Epoch   119: reducing learning rate of group 0 to 1.5259e-08.\n",
            "  119 ||   1.6413 |   0.5556 ||   1.2269 |   0.3216   0.4335   0.3335\n",
            "  120 ||   1.6738 |   0.5255 ||   1.2881 |   0.3150   0.4094   0.3400\n",
            "  121 ||   1.6321 |   0.5606 ||   1.2729 |   0.3354   0.4221   0.3522\n",
            "  122 ||   1.6525 |   0.5521 ||   1.2800 |   0.3120   0.4181   0.3335\n",
            "  123 ||   1.7011 |   0.5246 ||   1.1790 |   0.3457   0.4645   0.3691\n",
            "  124 ||   1.6654 |   0.5022 ||   1.2161 |   0.3431   0.4797   0.3648\n",
            "  125 ||   1.6760 |   0.5076 ||   1.2312 |   0.3439   0.4818   0.3823\n",
            "  126 ||   1.6698 |   0.5471 ||   1.1919 |   0.3421   0.4530   0.3584\n",
            "  127 ||   1.6776 |   0.5035 ||   1.2266 |   0.3266   0.3934   0.3267\n",
            "  128 ||   1.6814 |   0.5341 ||   1.2634 |   0.2729   0.4195   0.3124\n",
            "  129 ||   1.6243 |   0.5906 ||   1.2521 |   0.3283   0.4088   0.3406\n",
            "  130 ||   1.6538 |   0.5741 ||   1.1563 |   0.4092   0.4749   0.3874\n",
            "  131 ||   1.6951 |   0.5559 ||   1.2671 |   0.3539   0.4386   0.3693\n",
            "  132 ||   1.6871 |   0.5245 ||   1.2678 |   0.3222   0.4776   0.3619\n",
            "  133 ||   1.6575 |   0.5386 ||   1.1559 |   0.3567   0.5520   0.4084\n",
            "  134 ||   1.6941 |   0.5015 ||   1.2305 |   0.3137   0.4358   0.3458\n",
            "  135 ||   1.6456 |   0.5329 ||   1.2070 |   0.2953   0.4291   0.3309\n",
            "  136 ||   1.6658 |   0.5065 ||   1.1973 |   0.4052   0.4647   0.3830\n",
            "  137 ||   1.6592 |   0.5460 ||   1.2122 |   0.3771   0.4970   0.3854\n",
            "  138 ||   1.6815 |   0.5235 ||   1.1995 |   0.3300   0.4561   0.3589\n",
            "  139 ||   1.6341 |   0.5632 ||   1.2160 |   0.3366   0.4686   0.3624\n",
            "  140 ||   1.6516 |   0.5478 ||   1.2234 |   0.3670   0.4542   0.3708\n",
            "  141 ||   1.6312 |   0.5599 ||   1.2718 |   0.3208   0.4105   0.3400\n",
            "  142 ||   1.6482 |   0.5483 ||   1.2404 |   0.3317   0.4438   0.3545\n",
            "  143 ||   1.7258 |   0.5039 ||   1.2485 |   0.3212   0.4562   0.3498\n",
            "  144 ||   1.6622 |   0.5076 ||   1.2160 |   0.3041   0.4364   0.3359\n",
            "  145 ||   1.5927 |   0.5876 ||   1.2252 |   0.3967   0.4790   0.3915\n",
            "  146 ||   1.6653 |   0.5459 ||   1.1902 |   0.3934   0.4843   0.4020\n",
            "  147 ||   1.6870 |   0.5163 ||   1.2370 |   0.3526   0.4553   0.3644\n",
            "  148 ||   1.6678 |   0.4954 ||   1.2147 |   0.3136   0.4102   0.3219\n",
            "  149 ||   1.7292 |   0.4922 ||   1.2497 |   0.3273   0.4387   0.3497\n",
            "  150 ||   1.7036 |   0.4932 ||   1.2413 |   0.3089   0.4347   0.3337\n",
            "  151 ||   1.6096 |   0.5962 ||   1.1855 |   0.3288   0.4332   0.3472\n",
            "  152 ||   1.6613 |   0.5428 ||   1.1837 |   0.3990   0.4567   0.3912\n",
            "  153 ||   1.6815 |   0.5383 ||   1.1960 |   0.3238   0.4625   0.3543\n",
            "  154 ||   1.6381 |   0.5346 ||   1.2265 |   0.3349   0.4633   0.3628\n",
            "  155 ||   1.6520 |   0.5460 ||   1.2437 |   0.2875   0.3661   0.3056\n",
            "  156 ||   1.6554 |   0.5532 ||   1.2523 |   0.3375   0.4328   0.3658\n",
            "  157 ||   1.7151 |   0.5139 ||   1.2246 |   0.3027   0.4386   0.3317\n",
            "  158 ||   1.6599 |   0.5100 ||   1.2160 |   0.3650   0.4878   0.3827\n",
            "  159 ||   1.6584 |   0.5318 ||   1.1846 |   0.4009   0.4778   0.3930\n",
            "  160 ||   1.6540 |   0.5310 ||   1.1790 |   0.3567   0.5057   0.3861\n",
            "  161 ||   1.6058 |   0.5273 ||   1.2472 |   0.3406   0.4445   0.3568\n",
            "  162 ||   1.6427 |   0.5474 ||   1.1997 |   0.3296   0.4503   0.3503\n",
            "  163 ||   1.6858 |   0.5500 ||   1.2644 |   0.3486   0.4379   0.3559\n",
            "  164 ||   1.6775 |   0.5223 ||   1.2552 |   0.3139   0.4147   0.3351\n",
            "  165 ||   1.7313 |   0.4801 ||   1.2137 |   0.3443   0.4761   0.3766\n",
            "  166 ||   1.7244 |   0.4912 ||   1.1978 |   0.3436   0.4766   0.3734\n",
            "  167 ||   1.6833 |   0.5225 ||   1.2657 |   0.3174   0.4403   0.3412\n",
            "  168 ||   1.7019 |   0.5358 ||   1.2127 |   0.3365   0.4474   0.3645\n",
            "  169 ||   1.6943 |   0.5512 ||   1.2063 |   0.3766   0.5004   0.3980\n",
            "  170 ||   1.6150 |   0.5853 ||   1.2266 |   0.2929   0.4423   0.3344\n",
            "  171 ||   1.6496 |   0.6027 ||   1.2140 |   0.3819   0.5018   0.3846\n",
            "  172 ||   1.6625 |   0.5047 ||   1.2630 |   0.3244   0.4465   0.3570\n",
            "  173 ||   1.6633 |   0.5111 ||   1.2198 |   0.3345   0.4394   0.3571\n",
            "  174 ||   1.6508 |   0.5486 ||   1.2164 |   0.3388   0.4273   0.3479\n",
            "  175 ||   1.7230 |   0.4628 ||   1.2564 |   0.3074   0.4399   0.3345\n",
            "  176 ||   1.7067 |   0.5554 ||   1.1776 |   0.4025   0.5001   0.3980\n",
            "  177 ||   1.6715 |   0.5268 ||   1.2551 |   0.2889   0.4286   0.3242\n",
            "  178 ||   1.6765 |   0.4964 ||   1.2385 |   0.3031   0.4405   0.3373\n",
            "  179 ||   1.6864 |   0.5436 ||   1.2109 |   0.3769   0.5093   0.4012\n",
            "  180 ||   1.6526 |   0.5246 ||   1.2372 |   0.3218   0.4695   0.3626\n",
            "  181 ||   1.6874 |   0.5031 ||   1.2267 |   0.3446   0.4572   0.3645\n",
            "  182 ||   1.6547 |   0.5685 ||   1.1895 |   0.3683   0.4650   0.3708\n",
            "  183 ||   1.6724 |   0.5414 ||   1.2664 |   0.3395   0.4476   0.3618\n",
            "  184 ||   1.6625 |   0.5253 ||   1.1918 |   0.3744   0.4872   0.3980\n",
            "  185 ||   1.6511 |   0.5230 ||   1.2342 |   0.3280   0.4418   0.3473\n",
            "  186 ||   1.6889 |   0.5347 ||   1.2325 |   0.3079   0.4358   0.3414\n",
            "  187 ||   1.6774 |   0.5628 ||   1.2507 |   0.3252   0.4240   0.3447\n",
            "  188 ||   1.6939 |   0.4838 ||   1.2672 |   0.3112   0.4247   0.3329\n",
            "  189 ||   1.6367 |   0.5780 ||   1.1640 |   0.3425   0.4818   0.3741\n",
            "  190 ||   1.7019 |   0.4939 ||   1.2243 |   0.3270   0.4636   0.3580\n",
            "  191 ||   1.6723 |   0.5188 ||   1.2243 |   0.3597   0.4579   0.3714\n",
            "  192 ||   1.6618 |   0.5433 ||   1.2046 |   0.3723   0.5000   0.3916\n",
            "  193 ||   1.6710 |   0.5315 ||   1.2591 |   0.3189   0.3997   0.3352\n",
            "  194 ||   1.6820 |   0.5137 ||   1.2776 |   0.3112   0.4655   0.3479\n",
            "  195 ||   1.6971 |   0.5114 ||   1.1703 |   0.3810   0.4890   0.3927\n",
            "  196 ||   1.6500 |   0.5164 ||   1.2806 |   0.3313   0.4643   0.3564\n",
            "  197 ||   1.6529 |   0.5390 ||   1.2480 |   0.3218   0.4118   0.3360\n",
            "  198 ||   1.6768 |   0.5427 ||   1.2232 |   0.3423   0.4052   0.3419\n",
            "  199 ||   1.6326 |   0.5811 ||   1.1808 |   0.3199   0.4679   0.3591\n",
            "  200 ||   1.6532 |   0.5651 ||   1.1917 |   0.3760   0.4792   0.3874\n",
            "\n",
            "Training Completed\n",
            "\n",
            " Best ||        - |        - ||   1.1559 |   0.3567   0.5520   0.4084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(save_path + \"metrics.json\", 'w') as fw:\n",
        "    json.dump(metrics, fw)\n",
        "torch.save(model1, save_path + \"model.pt\")"
      ],
      "metadata": {
        "id": "8puyyAdDpiem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = COClassifier(len(vocab), embed_dim, len(label_vocab), charges['offence'], charges['sent_lens'], charges['doc_lens'], device, sent_label_wts, doc_label_wts, ptemb_matrix).to(device)\n",
        "model.load_state_dict(torch.load('saved/model.pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CCcBmPEKaUd",
        "outputId": "f789676e-c7e0-4e1e-f761-129785c6fd78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = infer(model, test_data, label_vocab, batch_size=5, device=device)\n",
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngmLj5HEKxE5",
        "outputId": "7fc2fde2-7718-45c8-d686-5986c0b2dd73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['criminal conspiracy',\n",
              "  'cheating',\n",
              "  'offence against state',\n",
              "  'forgery',\n",
              "  'criminal breach of trust'],\n",
              " [],\n",
              " [],\n",
              " ['murder', 'sexual offence', 'kidnapping', 'offence against public justice'],\n",
              " ['hurt',\n",
              "  'murder',\n",
              "  'unlawful assembly',\n",
              "  'mischief',\n",
              "  'theft',\n",
              "  'criminal intimidation',\n",
              "  'robbery',\n",
              "  'criminal trespass'],\n",
              " ['hurt',\n",
              "  'murder',\n",
              "  'unlawful assembly',\n",
              "  'mischief',\n",
              "  'robbery',\n",
              "  'criminal trespass'],\n",
              " ['hurt', 'murder', 'unlawful assembly', 'criminal trespass'],\n",
              " ['hurt',\n",
              "  'murder',\n",
              "  'criminal conspiracy',\n",
              "  'unlawful assembly',\n",
              "  'mischief',\n",
              "  'offence against public justice',\n",
              "  'offence against state',\n",
              "  'robbery'],\n",
              " ['marriage offence'],\n",
              " ['criminal conspiracy',\n",
              "  'offence against state',\n",
              "  'offence related to religion'],\n",
              " [],\n",
              " [],\n",
              " ['hurt',\n",
              "  'murder',\n",
              "  'criminal conspiracy',\n",
              "  'unlawful assembly',\n",
              "  'mischief',\n",
              "  'robbery',\n",
              "  'criminal trespass'],\n",
              " ['murder'],\n",
              " ['hurt', 'murder'],\n",
              " ['sexual offence'],\n",
              " ['hurt', 'murder', 'unlawful assembly', 'criminal trespass'],\n",
              " ['hurt', 'murder', 'offence affecting public safety'],\n",
              " ['hurt',\n",
              "  'murder',\n",
              "  'criminal conspiracy',\n",
              "  'unlawful assembly',\n",
              "  'offence against state'],\n",
              " ['hurt',\n",
              "  'murder',\n",
              "  'criminal conspiracy',\n",
              "  'unlawful assembly',\n",
              "  'mischief',\n",
              "  'robbery'],\n",
              " ['theft', 'criminal breach of trust', 'offence related to religion'],\n",
              " ['cheating', 'forgery', 'criminal breach of trust', 'cruelty by husband'],\n",
              " ['hurt', 'murder', 'criminal conspiracy', 'offence against public justice'],\n",
              " [],\n",
              " ['hurt', 'murder', 'offence affecting public safety'],\n",
              " ['murder', 'cruelty by husband'],\n",
              " ['criminal conspiracy',\n",
              "  'offence against public justice',\n",
              "  'cheating',\n",
              "  'cruelty by husband'],\n",
              " ['murder',\n",
              "  'kidnapping',\n",
              "  'offence against public justice',\n",
              "  'cruelty by husband'],\n",
              " ['murder', 'criminal breach of trust', 'cruelty by husband'],\n",
              " ['cheating', 'criminal breach of trust', 'cruelty by husband'],\n",
              " ['murder', 'sexual offence', 'kidnapping', 'offence against public justice'],\n",
              " ['hurt',\n",
              "  'murder',\n",
              "  'criminal conspiracy',\n",
              "  'unlawful assembly',\n",
              "  'mischief',\n",
              "  'offence against state',\n",
              "  'robbery'],\n",
              " ['criminal conspiracy', 'cheating', 'forgery', 'criminal breach of trust'],\n",
              " ['criminal conspiracy', 'offence against state'],\n",
              " ['criminal conspiracy',\n",
              "  'offence against public justice',\n",
              "  'cheating',\n",
              "  'criminal breach of trust'],\n",
              " ['murder', 'sexual offence', 'offence against public justice'],\n",
              " ['hurt',\n",
              "  'murder',\n",
              "  'unlawful assembly',\n",
              "  'offence against public justice',\n",
              "  'theft',\n",
              "  'robbery'],\n",
              " ['hurt', 'murder', 'unlawful assembly', 'criminal trespass'],\n",
              " ['theft'],\n",
              " ['criminal conspiracy', 'cheating', 'forgery', 'criminal breach of trust'],\n",
              " ['murder',\n",
              "  'criminal conspiracy',\n",
              "  'offence against public justice',\n",
              "  'cruelty by husband'],\n",
              " ['sexual offence', 'kidnapping', 'offence against public justice'],\n",
              " [],\n",
              " ['hurt',\n",
              "  'murder',\n",
              "  'criminal conspiracy',\n",
              "  'unlawful assembly',\n",
              "  'mischief',\n",
              "  'robbery'],\n",
              " ['murder', 'theft', 'cruelty by husband'],\n",
              " ['hurt', 'murder'],\n",
              " ['hurt', 'murder', 'unlawful assembly', 'criminal trespass'],\n",
              " ['murder', 'cruelty by husband'],\n",
              " ['hurt',\n",
              "  'murder',\n",
              "  'unlawful assembly',\n",
              "  'mischief',\n",
              "  'theft',\n",
              "  'robbery',\n",
              "  'criminal trespass'],\n",
              " ['sexual offence', 'criminal intimidation'],\n",
              " ['hurt', 'murder', 'unlawful assembly', 'mischief'],\n",
              " ['criminal conspiracy',\n",
              "  'cheating',\n",
              "  'criminal breach of trust',\n",
              "  'cruelty by husband'],\n",
              " ['cheating', 'criminal breach of trust', 'cruelty by husband'],\n",
              " ['hurt',\n",
              "  'murder',\n",
              "  'criminal conspiracy',\n",
              "  'unlawful assembly',\n",
              "  'mischief',\n",
              "  'offence against state',\n",
              "  'theft',\n",
              "  'robbery'],\n",
              " ['hurt', 'murder', 'unlawful assembly', 'criminal trespass'],\n",
              " ['murder', 'sexual offence', 'kidnapping', 'offence against public justice'],\n",
              " ['murder', 'sexual offence', 'kidnapping'],\n",
              " ['hurt', 'murder', 'criminal conspiracy', 'mischief', 'theft', 'robbery'],\n",
              " ['criminal conspiracy', 'offence against state'],\n",
              " ['hurt',\n",
              "  'murder',\n",
              "  'criminal conspiracy',\n",
              "  'unlawful assembly',\n",
              "  'offence against state'],\n",
              " ['murder', 'criminal conspiracy', 'mischief', 'robbery'],\n",
              " ['theft'],\n",
              " ['hurt',\n",
              "  'criminal conspiracy',\n",
              "  'unlawful assembly',\n",
              "  'mischief',\n",
              "  'theft',\n",
              "  'robbery',\n",
              "  'criminal trespass'],\n",
              " ['criminal conspiracy', 'mischief', 'offence against state', 'robbery'],\n",
              " ['murder',\n",
              "  'sexual offence',\n",
              "  'offence against public justice',\n",
              "  'cruelty by husband'],\n",
              " ['kidnapping'],\n",
              " ['kidnapping', 'cruelty by husband', 'marriage offence'],\n",
              " ['criminal conspiracy', 'offence against state', 'criminal breach of trust'],\n",
              " ['cheating', 'forgery', 'criminal breach of trust'],\n",
              " ['hurt',\n",
              "  'murder',\n",
              "  'criminal conspiracy',\n",
              "  'unlawful assembly',\n",
              "  'mischief',\n",
              "  'offence against state',\n",
              "  'theft',\n",
              "  'robbery']]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "td = {\"text\": [\"On August 25, 1976 at about 12 noon P.W. 1 Syed Ameer, Supervisor, Karnataka Electricity Board, went to the house of the respondent on a routine inspection to check the electric meter installed there.\",\n",
        "               \"He found the meter board at the entrance and though the meter was not recording consumption of electric energy, the lights and fans were on.\",\n",
        "               \"It appeared that the respondent had tampered with the main connection by fixing two switches to the wall of the house and by operating the switches the lights and fans inside the house could be used without the meter recording any consumption.\",\n",
        "               \"Later in the day, he along A with the Assistant Engineer attached to the Karnataka Electricity Board, Krishnarajanagar and the Junior Engineer went to the house of the respondent and saw that there was theft of electric energy.\"],\n",
        "      \"doc_labels\": [\"theft\"]}\n",
        "td['text'] = list(map(lambda x: tokenize_text(x), td['text']))\n",
        "test_one = [td]\n",
        "tokenize_dataset(test_one, vocab, label_vocab)\n",
        "infer(model, test_one, label_vocab, batch_size=1, device=device)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCk7jivxMK7S",
        "outputId": "62bef39b-0bbd-4128-cd3a-dd1169049286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['theft', 'robbery']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}